{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "Llama 3.3 70B Instruct",
  "description": "Llama 3.3 is a multilingual large language model optimized for dialogue use cases across multiple languages. It is a pretrained and instruction-tuned generative model with 70 billion parameters, outperforming many open-source and closed chat models on common industry benchmarks. Llama 3.3 supports a context length of 128,000 tokens and is designed for commercial and research use in multiple languages.",
  "release_date": "2024-12-06",
  "input_context_size": 128000,
  "output_context_size": 128000,
  "license": "Llama 3.3 Community License Agreement",
  "multimodal": false,
  "web_hydrated": false,
  "knowledge_cutoff": "2023-12",
  "api_ref_link": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
  "playground_link": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
  "paper_link": null,
  "scorecard_blog_link": null,
  "repo_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md",
  "weights_link": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct",
  "param_count": 70000000000,
  "training_tokens": 15000000000000,
  "qualitative_metrics": [
    {
      "dataset_name": "MMLU",
      "score": 0.86,
      "is_self_reported": true,
      "analysis_method": "0-shot CoT",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "MMLU-Pro",
      "score": 0.689,
      "is_self_reported": true,
      "analysis_method": "0-shot CoT",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "IFEval",
      "score": 0.921,
      "is_self_reported": true,
      "analysis_method": "Internal Evaluation",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "GPQA",
      "score": 0.505,
      "is_self_reported": true,
      "analysis_method": "0-shot CoT",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "HumanEval",
      "score": 0.884,
      "is_self_reported": true,
      "analysis_method": "Internal Evaluation",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "MBPP EvalPlus",
      "score": 0.876,
      "is_self_reported": true,
      "analysis_method": "Internal Evaluation",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "MATH",
      "score": 0.77,
      "is_self_reported": true,
      "analysis_method": "0-shot CoT",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "BFCL v2",
      "score": 0.773,
      "is_self_reported": true,
      "analysis_method": "Internal Evaluation",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    },
    {
      "dataset_name": "MGSM",
      "score": 0.911,
      "is_self_reported": true,
      "analysis_method": "Internal Evaluation",
      "date_recorded": "2024-12-06",
      "source_link": "https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md"
    }
  ]
}
