{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "Llama 3.2 11B Instruct",
  "description": "Llama 3.2 11B Vision Instruct is an instruction-tuned multimodal large language model optimized for visual recognition, image reasoning, captioning, and answering general questions about an image. It accepts text and images as input and generates text as output.",
  "release_date": "2024-09-25",
  "input_context_size": 128000,
  "output_context_size": 128000,
  "license": "Llama 3.2 Community License",
  "multimodal": true,
  "web_hydrated": false,
  "knowledge_cutoff": "2023-12-31",
  "api_ref_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
  "playground_link": null,
  "paper_link": null,
  "scorecard_blog_link": "https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/",
  "repo_link": "https://github.com/facebookresearch/llama",
  "weights_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct",
  "param_count": 10600000000,
  "training_tokens": null,
  "qualitative_metrics": [
    {
      "dataset_name": "VQAv2 (test)",
      "score": 0.752,
      "is_self_reported": true,
      "analysis_method": "Accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MMLU",
      "score": 0.73,
      "is_self_reported": true,
      "analysis_method": "Macro average accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MMMU",
      "score": 0.507,
      "is_self_reported": true,
      "analysis_method": "Val, 0-shot CoT, micro avg accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MMMU-Pro",
      "score": 0.33,
      "is_self_reported": true,
      "analysis_method": "Test accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MathVista",
      "score": 0.515,
      "is_self_reported": true,
      "analysis_method": "Test accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "ChartQA",
      "score": 0.834,
      "is_self_reported": true,
      "analysis_method": "Test, 0-shot CoT relaxed accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "AI2 Diagram",
      "score": 0.911,
      "is_self_reported": true,
      "analysis_method": "Test accuracy",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "DocVQA",
      "score": 0.884,
      "is_self_reported": true,
      "analysis_method": "Test ANLS",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MATH",
      "score": 0.519,
      "is_self_reported": true,
      "analysis_method": "0-shot, CoT",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "GPQA",
      "score": 0.328,
      "is_self_reported": true,
      "analysis_method": "0-shot, CoT",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    },
    {
      "dataset_name": "MGSM",
      "score": 0.689,
      "is_self_reported": true,
      "analysis_method": "0-shot, CoT",
      "date_recorded": "2024-09-25",
      "source_link": "https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct"
    }
  ]
}
