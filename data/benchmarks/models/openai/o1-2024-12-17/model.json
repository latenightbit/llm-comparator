{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "o1",
  "description": "A research preview model focused on mathematical and logical reasoning capabilities, demonstrating improved performance on tasks requiring step-by-step reasoning, mathematical problem-solving, and code generation. The model shows enhanced capabilities in formal reasoning while maintaining strong general capabilities.",
  "release_date": "2024-12-17",
  "input_context_size": 200000,
  "output_context_size": 100000,
  "license": "Proprietary",
  "multimodal": false,
  "web_hydrated": false,
  "knowledge_cutoff": "2024-01",
  "api_ref_link": "https://platform.openai.com/docs/models",
  "playground_link": null,
  "paper_link": "https://cdn.openai.com/o1-system-card-20240917.pdf",
  "scorecard_blog_link": "https://openai.com/index/learning-to-reason-with-llms",
  "repo_link": "https://openai.com/index/o1-and-new-tools-for-developers/",
  "weights_link": null,
  "param_count": null,
  "training_tokens": null,
  "qualitative_metrics": [
    {
      "dataset_name": "MATH",
      "score": 0.964,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MMLU",
      "score": 0.918,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "GSM8K",
      "score": 0.971,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "HumanEval",
      "score": 0.881,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "AIME 2024",
      "score": 0.833,
      "is_self_reported": true,
      "analysis_method": "accuracy",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "Codeforces",
      "score": 0.47,
      "is_self_reported": true,
      "analysis_method": "elo divided by max elo",
      "date_recorded": "2024-12-20",
      "source_link": "https://www.youtube.com/live/SKBG1sqdyIU?si=lWccKHt8bnttuYta"
    },
    {
      "dataset_name": "GPQA",
      "score": 0.757,
      "is_self_reported": true,
      "analysis_method": "accuracy",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MMMU",
      "score": 0.773,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MathVista",
      "score": 0.71,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "GPQA Biology",
      "score": 0.692,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "GPQA Chemistry",
      "score": 0.647,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "GPQA Physics",
      "score": 0.928,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "SWE-bench",
      "score": 0.489,
      "is_self_reported": true,
      "analysis_method": "verified",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/o1-and-new-tools-for-developers/"
    },
    {
      "dataset_name": "LiveBench",
      "score": 0.766,
      "is_self_reported": true,
      "analysis_method": "coding",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/o1-and-new-tools-for-developers/"
    },
    {
      "dataset_name": "MGSM",
      "score": 0.893,
      "is_self_reported": true,
      "analysis_method": "pass@1",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/o1-and-new-tools-for-developers/"
    },
    {
      "dataset_name": "SimpleQA",
      "score": 0.426,
      "is_self_reported": true,
      "analysis_method": "factuality",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/o1-and-new-tools-for-developers/"
    },
    {
      "dataset_name": "TAU-bench Retail",
      "score": 0.735,
      "is_self_reported": true,
      "analysis_method": "agents",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/o1-and-new-tools-for-developers/"
    },
    {
      "dataset_name": "TAU-bench Airline",
      "score": 0.542,
      "is_self_reported": true,
      "analysis_method": "agents",
      "date_recorded": "2024-03-13",
      "source_link": "https://openai.com/index/o1-and-new-tools-for-developers/"
    }
  ]
}
