{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "GPT-4o",
  "description": "GPT-4o ('o' for 'omni') is a multimodal AI model that accepts text, audio, image, and video inputs, and generates text, audio, and image outputs. It matches GPT-4 Turbo performance on text and code, with improvements in non-English languages, vision, and audio understanding.",
  "release_date": "2024-08-06",
  "input_context_size": 128000,
  "output_context_size": 16384,
  "license": "Proprietary",
  "multimodal": true,
  "web_hydrated": false,
  "knowledge_cutoff": null,
  "api_ref_link": "https://platform.openai.com/docs/api-reference",
  "playground_link": "https://chat.openai.com/",
  "paper_link": null,
  "scorecard_blog_link": "https://openai.com/index/hello-gpt-4o/",
  "repo_link": null,
  "weights_link": null,
  "param_count": null,
  "training_tokens": null,
  "qualitative_metrics": [
    {
      "dataset_name": "AIME 2024",
      "score": 0.134,
      "is_self_reported": true,
      "analysis_method": "consistency at 64 samples",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "Codeforces",
      "score": 0.11,
      "is_self_reported": true,
      "analysis_method": "percentile ranking",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "GPQA",
      "score": 0.536,
      "is_self_reported": true,
      "analysis_method": "pass at 1 attempt",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MMLU",
      "score": 0.88,
      "is_self_reported": true,
      "analysis_method": "pass at 1 attempt",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MMMU",
      "score": 0.691,
      "is_self_reported": true,
      "analysis_method": "pass at 1 attempt on validation set",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MathVista",
      "score": 0.638,
      "is_self_reported": true,
      "analysis_method": "pass at 1 attempt on testmini set",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/learning-to-reason-with-llms/"
    },
    {
      "dataset_name": "MMLU-Pro",
      "score": 0.747,
      "is_self_reported": true,
      "analysis_method": "0-shot CoT",
      "date_recorded": "2024-08-06",
      "source_link": "https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro"
    },
    {
      "dataset_name": "AI2D",
      "score": 0.942,
      "is_self_reported": true,
      "analysis_method": "test set evaluation",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/hello-gpt-4o/"
    },
    {
      "dataset_name": "ChartQA",
      "score": 0.857,
      "is_self_reported": true,
      "analysis_method": "test set evaluation",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/hello-gpt-4o/"
    },
    {
      "dataset_name": "DocVQA",
      "score": 0.928,
      "is_self_reported": true,
      "analysis_method": "test set evaluation",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/hello-gpt-4o/"
    },
    {
      "dataset_name": "ActivityNet",
      "score": 0.619,
      "is_self_reported": true,
      "analysis_method": "test set evaluation",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/hello-gpt-4o/"
    },
    {
      "dataset_name": "EgoSchema",
      "score": 0.722,
      "is_self_reported": true,
      "analysis_method": "test set evaluation",
      "date_recorded": "2024-05-08",
      "source_link": "https://openai.com/index/hello-gpt-4o/"
    }
  ]
}
