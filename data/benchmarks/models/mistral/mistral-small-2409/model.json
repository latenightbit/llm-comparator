{
  "canonical_model_id": null,
  "fine_tuned_from_model_id": null,
  "name": "Mistral Small",
  "description": "An enterprise-grade 22B parameter model optimized for tasks like translation, summarization, and sentiment analysis. Offers significant improvements in human alignment, reasoning capabilities, and code generation compared to previous versions.",
  "release_date": "2024-09-17",
  "input_context_size": 32768,
  "output_context_size": 32768,
  "license": "Mistral Research License",
  "multimodal": false,
  "web_hydrated": false,
  "knowledge_cutoff": null,
  "api_ref_link": "https://docs.mistral.ai/api/",
  "playground_link": "https://console.mistral.ai/",
  "paper_link": null,
  "scorecard_blog_link": "https://mistral.ai/news/september-24-release/",
  "repo_link": null,
  "weights_link": "https://huggingface.co/mistralai/Mistral-Small-Instruct-2409",
  "param_count": 22000000000,
  "training_tokens": null,
  "qualitative_metrics": []
}
